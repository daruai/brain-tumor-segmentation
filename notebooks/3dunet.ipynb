{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source: https://www.kaggle.com/awsaf49/brats20-dataset-training-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "royal-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import Compose, HorizontalFlip\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerous-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/polomarco/brats20-3dunet-3dautoencoder\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "          )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    \n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "            \n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet3d(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "existing-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, phase: str=\"test\", is_resize: bool=False):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.augmentations = get_augmentations(phase)\n",
    "        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n",
    "        self.is_resize = is_resize\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        id_ = self.df.loc[idx, 'Brats20ID']\n",
    "        root_path = self.df.loc[self.df['Brats20ID'] == id_]['path'].values[0]\n",
    "        # load all modalities\n",
    "        images = []\n",
    "        for data_type in self.data_types:\n",
    "            img_path = os.path.join(root_path, id_ + data_type)\n",
    "            img = self.load_img(img_path)#.transpose(2, 0, 1)\n",
    "            \n",
    "            if self.is_resize:\n",
    "                img = self.resize(img)\n",
    "    \n",
    "            img = self.normalize(img)\n",
    "            images.append(img)\n",
    "        img = np.stack(images)\n",
    "        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "        \n",
    "        if self.phase != \"test\":\n",
    "            mask_path =  os.path.join(root_path, id_ + \"_seg.nii\")\n",
    "            mask = self.load_img(mask_path)\n",
    "            \n",
    "            if self.is_resize:\n",
    "                mask = self.resize(mask)\n",
    "                mask = np.clip(mask.astype(np.uint8), 0, 1).astype(np.float32)\n",
    "                mask = np.clip(mask, 0, 1)\n",
    "            mask = self.preprocess_mask_labels(mask)\n",
    "    \n",
    "            augmented = self.augmentations(image=img.astype(np.float32), \n",
    "                                           mask=mask.astype(np.float32))\n",
    "            \n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "    \n",
    "        \n",
    "            return {\n",
    "                \"Id\": id_,\n",
    "                \"image\": img,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"Id\": id_,\n",
    "            \"image\": img,\n",
    "        }\n",
    "    \n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path) # TODO: Modify the image reading\n",
    "        data = np.asarray(data.dataobj)\n",
    "        return data\n",
    "    \n",
    "    def normalize(self, data: np.ndarray):\n",
    "        data_min = np.min(data)\n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "    \n",
    "    def resize(self, data: np.ndarray):\n",
    "        data = resize(data, (78, 120, 120), preserve_range=True)\n",
    "        return data\n",
    "    \n",
    "    def preprocess_mask_labels(self, mask: np.ndarray):\n",
    "\n",
    "        mask_WT = mask.copy()\n",
    "        mask_WT[mask_WT == 1] = 1\n",
    "        mask_WT[mask_WT == 2] = 1\n",
    "        mask_WT[mask_WT == 4] = 1\n",
    "\n",
    "        mask_TC = mask.copy()\n",
    "        mask_TC[mask_TC == 1] = 1\n",
    "        mask_TC[mask_TC == 2] = 0\n",
    "        mask_TC[mask_TC == 4] = 1\n",
    "\n",
    "        mask_ET = mask.copy()\n",
    "        mask_ET[mask_ET == 1] = 0\n",
    "        mask_ET[mask_ET == 2] = 0\n",
    "        mask_ET[mask_ET == 4] = 1\n",
    "\n",
    "        mask = np.stack([mask_WT, mask_TC, mask_ET])\n",
    "        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "\n",
    "        return mask       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "warming-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentations(phase):\n",
    "    list_transforms = []\n",
    "    \n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    path_to_csv: str,\n",
    "    phase: str,\n",
    "    fold: int = 0,\n",
    "    batch_size: int = 1,\n",
    "    num_workers: int = 4,\n",
    "):\n",
    "    '''Returns: dataloader for the model training'''\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    \n",
    "    train_df = df.loc[df['fold'] != fold].reset_index(drop=True)\n",
    "    val_df = df.loc[df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    dataset = dataset(df, phase)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "senior-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config\n",
    "\n",
    "class GlobalConfig:\n",
    "    root_dir = 'input/brats20-dataset-training-validation'\n",
    "    train_root_dir = 'input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "    test_root_dir = 'input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "    path_to_csv = 'train_data.csv'\n",
    "    pretrained_model_path = 'input/brats20logs/brats2020logs/unet/last_epoch_model.pth'\n",
    "    train_logs_path = 'input/brats20logs/brats2020logs/unet/train_log.csv'\n",
    "    ae_pretrained_model_path = 'input/brats20logs/brats2020logs/ae/autoencoder_best_model.pth'\n",
    "    tab_data = 'input/brats20logs/brats2020logs/data/df_with_voxel_stats_and_latent_features.csv'\n",
    "    seed = 55\n",
    "    \n",
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "config = GlobalConfig()\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "canadian-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df -> (201, 12) val_df -> (34, 12) test_df -> (133, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=7.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "## Prepare training, validation and testing datasets\n",
    "\n",
    "survival_info_df = pd.read_csv('input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/survival_info.csv')\n",
    "name_mapping_df = pd.read_csv('input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/name_mapping.csv')\n",
    "\n",
    "name_mapping_df.rename({'BraTS_2020_subject_ID': 'Brats20ID'}, axis=1, inplace=True) \n",
    "\n",
    "\n",
    "df = survival_info_df.merge(name_mapping_df, on=\"Brats20ID\", how=\"right\")\n",
    "\n",
    "paths = []\n",
    "for _, row  in df.iterrows():\n",
    "    \n",
    "    id_ = row['Brats20ID']\n",
    "    phase = id_.split(\"_\")[-2]\n",
    "    \n",
    "    if phase == 'Training':\n",
    "        path = os.path.join(config.train_root_dir, id_)\n",
    "    else:\n",
    "        path = os.path.join(config.test_root_dir, id_)\n",
    "    paths.append(path)\n",
    "    \n",
    "df['path'] = paths\n",
    "\n",
    "#split data on train, test, split\n",
    "#train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=69, shuffle=True)\n",
    "#train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n",
    "\n",
    "train_data = df.loc[df['Age'].notnull()].reset_index(drop=True)\n",
    "train_data[\"Age_rank\"] =  train_data[\"Age\"] // 10 * 10\n",
    "train_data = train_data.loc[train_data['Brats20ID'] != 'BraTS20_Training_355'].reset_index(drop=True, )\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=7, random_state=config.seed, shuffle=True\n",
    ")\n",
    "for i, (train_index, val_index) in enumerate(\n",
    "        skf.split(train_data, train_data[\"Age_rank\"])\n",
    "        ):\n",
    "        train_data.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train_df = train_data.loc[train_data['fold'] != 0].reset_index(drop=True)\n",
    "val_df = train_data.loc[train_data['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "test_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\n",
    "print(\"train_df ->\", train_df.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)\n",
    "train_data.to_csv(\"train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "marked-wesley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brats20ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survival_days</th>\n",
       "      <th>Extent_of_Resection</th>\n",
       "      <th>Grade</th>\n",
       "      <th>BraTS_2017_subject_ID</th>\n",
       "      <th>BraTS_2018_subject_ID</th>\n",
       "      <th>TCGA_TCIA_subject_ID</th>\n",
       "      <th>BraTS_2019_subject_ID</th>\n",
       "      <th>path</th>\n",
       "      <th>Age_rank</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>60.463</td>\n",
       "      <td>289</td>\n",
       "      <td>GTR</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AAB_1</td>\n",
       "      <td>Brats18_CBICA_AAB_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AAB_1</td>\n",
       "      <td>input/brats20-dataset-training-validation/BraT...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS20_Training_002</td>\n",
       "      <td>52.263</td>\n",
       "      <td>616</td>\n",
       "      <td>GTR</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AAG_1</td>\n",
       "      <td>Brats18_CBICA_AAG_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AAG_1</td>\n",
       "      <td>input/brats20-dataset-training-validation/BraT...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS20_Training_003</td>\n",
       "      <td>54.301</td>\n",
       "      <td>464</td>\n",
       "      <td>GTR</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AAL_1</td>\n",
       "      <td>Brats18_CBICA_AAL_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AAL_1</td>\n",
       "      <td>input/brats20-dataset-training-validation/BraT...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS20_Training_004</td>\n",
       "      <td>39.068</td>\n",
       "      <td>788</td>\n",
       "      <td>GTR</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AAP_1</td>\n",
       "      <td>Brats18_CBICA_AAP_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AAP_1</td>\n",
       "      <td>input/brats20-dataset-training-validation/BraT...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS20_Training_005</td>\n",
       "      <td>68.493</td>\n",
       "      <td>465</td>\n",
       "      <td>GTR</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_ABB_1</td>\n",
       "      <td>Brats18_CBICA_ABB_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_ABB_1</td>\n",
       "      <td>input/brats20-dataset-training-validation/BraT...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brats20ID     Age Survival_days Extent_of_Resection Grade  \\\n",
       "0  BraTS20_Training_001  60.463           289                 GTR   HGG   \n",
       "1  BraTS20_Training_002  52.263           616                 GTR   HGG   \n",
       "2  BraTS20_Training_003  54.301           464                 GTR   HGG   \n",
       "3  BraTS20_Training_004  39.068           788                 GTR   HGG   \n",
       "4  BraTS20_Training_005  68.493           465                 GTR   HGG   \n",
       "\n",
       "  BraTS_2017_subject_ID BraTS_2018_subject_ID TCGA_TCIA_subject_ID  \\\n",
       "0   Brats17_CBICA_AAB_1   Brats18_CBICA_AAB_1                  NaN   \n",
       "1   Brats17_CBICA_AAG_1   Brats18_CBICA_AAG_1                  NaN   \n",
       "2   Brats17_CBICA_AAL_1   Brats18_CBICA_AAL_1                  NaN   \n",
       "3   Brats17_CBICA_AAP_1   Brats18_CBICA_AAP_1                  NaN   \n",
       "4   Brats17_CBICA_ABB_1   Brats18_CBICA_ABB_1                  NaN   \n",
       "\n",
       "  BraTS_2019_subject_ID                                               path  \\\n",
       "0   BraTS19_CBICA_AAB_1  input/brats20-dataset-training-validation/BraT...   \n",
       "1   BraTS19_CBICA_AAG_1  input/brats20-dataset-training-validation/BraT...   \n",
       "2   BraTS19_CBICA_AAL_1  input/brats20-dataset-training-validation/BraT...   \n",
       "3   BraTS19_CBICA_AAP_1  input/brats20-dataset-training-validation/BraT...   \n",
       "4   BraTS19_CBICA_ABB_1  input/brats20-dataset-training-validation/BraT...   \n",
       "\n",
       "   Age_rank  fold  \n",
       "0      60.0   1.0  \n",
       "1      50.0   3.0  \n",
       "2      50.0   0.0  \n",
       "3      30.0   3.0  \n",
       "4      60.0   0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "supported-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='train_data.csv', phase='valid', fold=0)\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demographic-watson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['BraTS20_Training_168'],\n",
       " torch.Size([1, 4, 155, 240, 240]),\n",
       " torch.Size([1, 3, 155, 240, 240]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(dataloader))\n",
    "data['Id'], data['image'].shape, data['mask'].shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
